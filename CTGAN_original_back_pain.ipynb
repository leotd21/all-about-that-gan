{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leotd21/all-about-that-gan/blob/main/CTGAN_original_back_pain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzUHIGiNnAUj"
      },
      "source": [
        "# transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbjlgqu0SG8a"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.mixture import BayesianGaussianMixture\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.utils._testing import ignore_warnings\n",
        "\n",
        "\n",
        "class DataTransformer(object):\n",
        "    \"\"\"Data Transformer.\n",
        "\n",
        "    Model continuous columns with a BayesianGMM and normalized to a scalar\n",
        "    [0, 1] and a vector.\n",
        "    Discrete columns are encoded using a scikit-learn OneHotEncoder.\n",
        "\n",
        "    Args:\n",
        "        n_cluster (int):\n",
        "            Number of modes.\n",
        "        epsilon (float):\n",
        "            Epsilon value.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters=10, epsilon=0.005):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    @ignore_warnings(category=ConvergenceWarning)\n",
        "    def _fit_continuous(self, column, data):\n",
        "        gm = BayesianGaussianMixture(\n",
        "            self.n_clusters,\n",
        "            weight_concentration_prior_type='dirichlet_process',\n",
        "            weight_concentration_prior=0.001,\n",
        "            n_init=1\n",
        "        )\n",
        "        gm.fit(data)\n",
        "        components = gm.weights_ > self.epsilon\n",
        "        num_components = components.sum()\n",
        "\n",
        "        return {\n",
        "            'name': column,\n",
        "            'model': gm,\n",
        "            'components': components,\n",
        "            'output_info': [(1, 'tanh'), (num_components, 'softmax')],\n",
        "            'output_dimensions': 1 + num_components,\n",
        "        }\n",
        "\n",
        "    def _fit_discrete(self, column, data):\n",
        "        ohe = OneHotEncoder(sparse=False)\n",
        "        ohe.fit(data)\n",
        "        categories = len(ohe.categories_[0])\n",
        "\n",
        "        return {\n",
        "            'name': column,\n",
        "            'encoder': ohe,\n",
        "            'output_info': [(categories, 'softmax')],\n",
        "            'output_dimensions': categories\n",
        "        }\n",
        "\n",
        "    def fit(self, data, discrete_columns=tuple()):\n",
        "        self.output_info = []\n",
        "        self.output_dimensions = 0\n",
        "\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            self.dataframe = False\n",
        "            data = pd.DataFrame(data)\n",
        "        else:\n",
        "            self.dataframe = True\n",
        "\n",
        "        self.dtypes = data.infer_objects().dtypes\n",
        "        self.meta = []\n",
        "        for column in data.columns:\n",
        "            column_data = data[[column]].values\n",
        "            if column in discrete_columns:\n",
        "                meta = self._fit_discrete(column, column_data)\n",
        "            else:\n",
        "                meta = self._fit_continuous(column, column_data)\n",
        "\n",
        "            self.output_info += meta['output_info']\n",
        "            self.output_dimensions += meta['output_dimensions']\n",
        "            self.meta.append(meta)\n",
        "\n",
        "    def _transform_continuous(self, column_meta, data):\n",
        "        components = column_meta['components']\n",
        "        model = column_meta['model']\n",
        "\n",
        "        means = model.means_.reshape((1, self.n_clusters))\n",
        "        stds = np.sqrt(model.covariances_).reshape((1, self.n_clusters))\n",
        "        features = (data - means) / (4 * stds)\n",
        "\n",
        "        probs = model.predict_proba(data)\n",
        "\n",
        "        n_opts = components.sum()\n",
        "        features = features[:, components]\n",
        "        probs = probs[:, components]\n",
        "\n",
        "        opt_sel = np.zeros(len(data), dtype='int')\n",
        "        for i in range(len(data)):\n",
        "            pp = probs[i] + 1e-6\n",
        "            pp = pp / pp.sum()\n",
        "            opt_sel[i] = np.random.choice(np.arange(n_opts), p=pp)\n",
        "\n",
        "        idx = np.arange((len(features)))\n",
        "        features = features[idx, opt_sel].reshape([-1, 1])\n",
        "        features = np.clip(features, -.99, .99)\n",
        "\n",
        "        probs_onehot = np.zeros_like(probs)\n",
        "        probs_onehot[np.arange(len(probs)), opt_sel] = 1\n",
        "        return [features, probs_onehot]\n",
        "\n",
        "    def _transform_discrete(self, column_meta, data):\n",
        "        encoder = column_meta['encoder']\n",
        "        return encoder.transform(data)\n",
        "\n",
        "    def transform(self, data):\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            data = pd.DataFrame(data)\n",
        "\n",
        "        values = []\n",
        "        for meta in self.meta:\n",
        "            column_data = data[[meta['name']]].values\n",
        "            if 'model' in meta:\n",
        "                values += self._transform_continuous(meta, column_data)\n",
        "            else:\n",
        "                values.append(self._transform_discrete(meta, column_data))\n",
        "\n",
        "        return np.concatenate(values, axis=1).astype(float)\n",
        "\n",
        "    def _inverse_transform_continuous(self, meta, data, sigma):\n",
        "        model = meta['model']\n",
        "        components = meta['components']\n",
        "\n",
        "        u = data[:, 0]\n",
        "        v = data[:, 1:]\n",
        "\n",
        "        if sigma is not None:\n",
        "            u = np.random.normal(u, sigma)\n",
        "\n",
        "        u = np.clip(u, -1, 1)\n",
        "        v_t = np.ones((len(data), self.n_clusters)) * -100\n",
        "        v_t[:, components] = v\n",
        "        v = v_t\n",
        "        means = model.means_.reshape([-1])\n",
        "        stds = np.sqrt(model.covariances_).reshape([-1])\n",
        "        p_argmax = np.argmax(v, axis=1)\n",
        "        std_t = stds[p_argmax]\n",
        "        mean_t = means[p_argmax]\n",
        "        column = u * 4 * std_t + mean_t\n",
        "\n",
        "        return column\n",
        "\n",
        "    def _inverse_transform_discrete(self, meta, data):\n",
        "        encoder = meta['encoder']\n",
        "        return encoder.inverse_transform(data)\n",
        "\n",
        "    def inverse_transform(self, data, sigmas):\n",
        "        start = 0\n",
        "        output = []\n",
        "        column_names = []\n",
        "        for meta in self.meta:\n",
        "            dimensions = meta['output_dimensions']\n",
        "            columns_data = data[:, start:start + dimensions]\n",
        "\n",
        "            if 'model' in meta:\n",
        "                sigma = sigmas[start] if sigmas else None\n",
        "                inverted = self._inverse_transform_continuous(meta, columns_data, sigma)\n",
        "            else:\n",
        "                inverted = self._inverse_transform_discrete(meta, columns_data)\n",
        "\n",
        "            output.append(inverted)\n",
        "            column_names.append(meta['name'])\n",
        "            start += dimensions\n",
        "\n",
        "        output = np.column_stack(output)\n",
        "        output = pd.DataFrame(output, columns=column_names).astype(self.dtypes)\n",
        "        if not self.dataframe:\n",
        "            output = output.values\n",
        "\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKIv7Q52nISo"
      },
      "source": [
        "# sampler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WqqSz9nR2Mx"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sampler(object):\n",
        "    \"\"\"docstring for Sampler.\"\"\"\n",
        "\n",
        "    def __init__(self, data, output_info):\n",
        "        super(Sampler, self).__init__()\n",
        "        self.data = data\n",
        "        self.model = []\n",
        "        self.n = len(data)\n",
        "\n",
        "        st = 0\n",
        "        skip = False\n",
        "        for item in output_info:\n",
        "            if item[1] == 'tanh':\n",
        "                st += item[0]\n",
        "                skip = True\n",
        "            elif item[1] == 'softmax':\n",
        "                if skip:\n",
        "                    skip = False\n",
        "                    st += item[0]\n",
        "                    continue\n",
        "\n",
        "                ed = st + item[0]\n",
        "                tmp = []\n",
        "                for j in range(item[0]):\n",
        "                    tmp.append(np.nonzero(data[:, st + j])[0])\n",
        "\n",
        "                self.model.append(tmp)\n",
        "                st = ed\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "        assert st == data.shape[1]\n",
        "\n",
        "    def sample(self, n, col, opt):\n",
        "        if col is None:\n",
        "            idx = np.random.choice(np.arange(self.n), n)\n",
        "            return self.data[idx]\n",
        "\n",
        "        idx = []\n",
        "        for c, o in zip(col, opt):\n",
        "            idx.append(np.random.choice(self.model[c][o]))\n",
        "\n",
        "        return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsoHXQcWnLHU"
      },
      "source": [
        "# models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n5Xuqt_Rlw6"
      },
      "source": [
        "import torch\n",
        "from torch.nn import BatchNorm1d, Dropout, LeakyReLU, Linear, Module, ReLU, Sequential\n",
        "\n",
        "\n",
        "class Discriminator(Module):\n",
        "\n",
        "    def calc_gradient_penalty(self, real_data, fake_data, device='cpu', pac=10, lambda_=10):\n",
        "\n",
        "        alpha = torch.rand(real_data.size(0) // pac, 1, 1, device=device)\n",
        "        #.size returns the size of dataframe\n",
        "        #.rand returns a random tensor filled with random numbers from a uniform\n",
        "        #distribution from 0 to 1\n",
        "        #\n",
        "        alpha = alpha.repeat(1, pac, real_data.size(1))\n",
        "        alpha = alpha.view(-1, real_data.size(1))\n",
        "\n",
        "        interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n",
        "\n",
        "        disc_interpolates = self(interpolates)\n",
        "\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=disc_interpolates, inputs=interpolates,\n",
        "            grad_outputs=torch.ones(disc_interpolates.size(), device=device),\n",
        "            create_graph=True, retain_graph=True, only_inputs=True\n",
        "        )[0]\n",
        "\n",
        "        gradient_penalty = ((\n",
        "            gradients.view(-1, pac * real_data.size(1)).norm(2, dim=1) - 1\n",
        "        ) ** 2).mean() * lambda_\n",
        "\n",
        "        return gradient_penalty\n",
        "\n",
        "    def __init__(self, input_dim, dis_dims, pack=10):\n",
        "        super(Discriminator, self).__init__()\n",
        "        dim = input_dim * pack\n",
        "        self.pack = pack\n",
        "        self.packdim = dim\n",
        "        seq = []\n",
        "        for item in list(dis_dims):\n",
        "            seq += [Linear(dim, item), LeakyReLU(0.2), Dropout(0.5)]\n",
        "            dim = item\n",
        "\n",
        "        seq += [Linear(dim, 1)]\n",
        "        self.seq = Sequential(*seq)\n",
        "\n",
        "    def forward(self, input):\n",
        "        assert input.size()[0] % self.pack == 0\n",
        "        return self.seq(input.view(-1, self.packdim))\n",
        "\n",
        "\n",
        "class Residual(Module):\n",
        "    def __init__(self, i, o):\n",
        "        super(Residual, self).__init__()\n",
        "        self.fc = Linear(i, o)\n",
        "        self.bn = BatchNorm1d(o)\n",
        "        self.relu = ReLU()\n",
        "\n",
        "    def forward(self, input):\n",
        "        out = self.fc(input)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        return torch.cat([out, input], dim=1)\n",
        "\n",
        "\n",
        "class Generator(Module):\n",
        "    def __init__(self, embedding_dim, gen_dims, data_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        dim = embedding_dim\n",
        "        seq = []\n",
        "        for item in list(gen_dims):\n",
        "            seq += [Residual(dim, item)]\n",
        "            dim += item\n",
        "        seq.append(Linear(dim, data_dim))\n",
        "        self.seq = Sequential(*seq)\n",
        "\n",
        "    def forward(self, input):\n",
        "        data = self.seq(input)\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoV9y2oInQbt"
      },
      "source": [
        "# conditional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X0eSQu_Q9_a"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class ConditionalGenerator(object):\n",
        "    def __init__(self, data, output_info, log_frequency):\n",
        "        self.model = []\n",
        "\n",
        "        start = 0\n",
        "        skip = False\n",
        "        max_interval = 0\n",
        "        counter = 0\n",
        "        for item in output_info:\n",
        "            if item[1] == 'tanh':\n",
        "                start += item[0]\n",
        "                skip = True\n",
        "                continue\n",
        "\n",
        "            elif item[1] == 'softmax':\n",
        "                if skip:\n",
        "                    skip = False\n",
        "                    start += item[0]\n",
        "                    continue\n",
        "\n",
        "                end = start + item[0]\n",
        "                max_interval = max(max_interval, end - start)\n",
        "                counter += 1\n",
        "                self.model.append(np.argmax(data[:, start:end], axis=-1))\n",
        "                start = end\n",
        "\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "        assert start == data.shape[1]\n",
        "\n",
        "        self.interval = []\n",
        "        self.n_col = 0\n",
        "        self.n_opt = 0\n",
        "        skip = False\n",
        "        start = 0\n",
        "        self.p = np.zeros((counter, max_interval))\n",
        "        for item in output_info:\n",
        "            if item[1] == 'tanh':\n",
        "                skip = True\n",
        "                start += item[0]\n",
        "                continue\n",
        "            elif item[1] == 'softmax':\n",
        "                if skip:\n",
        "                    start += item[0]\n",
        "                    skip = False\n",
        "                    continue\n",
        "                end = start + item[0]\n",
        "                tmp = np.sum(data[:, start:end], axis=0)\n",
        "                if log_frequency:\n",
        "                    tmp = np.log(tmp + 1)\n",
        "                tmp = tmp / np.sum(tmp)\n",
        "                self.p[self.n_col, :item[0]] = tmp\n",
        "                self.interval.append((self.n_opt, item[0]))\n",
        "                self.n_opt += item[0]\n",
        "                self.n_col += 1\n",
        "                start = end\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "        self.interval = np.asarray(self.interval)\n",
        "\n",
        "    def random_choice_prob_index(self, idx):\n",
        "        a = self.p[idx]\n",
        "        r = np.expand_dims(np.random.rand(a.shape[0]), axis=1)\n",
        "        return (a.cumsum(axis=1) > r).argmax(axis=1)\n",
        "\n",
        "    def sample(self, batch):\n",
        "        if self.n_col == 0:\n",
        "            return None\n",
        "\n",
        "        batch = batch\n",
        "        idx = np.random.choice(np.arange(self.n_col), batch)\n",
        "\n",
        "        vec1 = np.zeros((batch, self.n_opt), dtype='float32')\n",
        "        mask1 = np.zeros((batch, self.n_col), dtype='float32')\n",
        "        mask1[np.arange(batch), idx] = 1\n",
        "        opt1prime = self.random_choice_prob_index(idx)\n",
        "        opt1 = self.interval[idx, 0] + opt1prime\n",
        "        vec1[np.arange(batch), opt1] = 1\n",
        "\n",
        "        return vec1, mask1, idx, opt1prime\n",
        "\n",
        "    def sample_zero(self, batch):\n",
        "        if self.n_col == 0:\n",
        "            return None\n",
        "\n",
        "        vec = np.zeros((batch, self.n_opt), dtype='float32')\n",
        "        idx = np.random.choice(np.arange(self.n_col), batch)\n",
        "        for i in range(batch):\n",
        "            col = idx[i]\n",
        "            pick = int(np.random.choice(self.model[col]))\n",
        "            vec[i, pick + self.interval[col, 0]] = 1\n",
        "\n",
        "        return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNZH3Zw7naq-"
      },
      "source": [
        "# data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewb92MlnRBNH"
      },
      "source": [
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_csv(csv_filename, meta_filename=None, header=True, discrete=None):\n",
        "\n",
        "    data = pd.read_csv(csv_filename, header='infer' if header else None)\n",
        "\n",
        "    if meta_filename:\n",
        "        with open(meta_filename) as meta_file:\n",
        "            metadata = json.load(meta_file)\n",
        "\n",
        "        discrete_columns = [\n",
        "            column['name']\n",
        "            for column in metadata['columns']\n",
        "            if column['type'] != 'continuous'\n",
        "        ]\n",
        "\n",
        "    elif discrete:\n",
        "        discrete_columns = discrete.split(',')\n",
        "        if not header:\n",
        "            discrete_columns = [int(i) for i in discrete_columns]\n",
        "\n",
        "    else:\n",
        "        discrete_columns = []\n",
        "\n",
        "    return data, discrete_columns\n",
        "\n",
        "\n",
        "def read_tsv(data_filename, meta_filename):\n",
        "    with open(meta_filename) as f:\n",
        "        column_info = f.readlines()\n",
        "\n",
        "    column_info_raw = [\n",
        "        x.replace(\"{\", \" \").replace(\"}\", \" \").split()\n",
        "        for x in column_info\n",
        "    ]\n",
        "\n",
        "    discrete = []\n",
        "    continuous = []\n",
        "    column_info = []\n",
        "\n",
        "    for idx, item in enumerate(column_info_raw):\n",
        "        if item[0] == 'C':\n",
        "            continuous.append(idx)\n",
        "            column_info.append((float(item[1]), float(item[2])))\n",
        "        else:\n",
        "            assert item[0] == 'D'\n",
        "            discrete.append(idx)\n",
        "            column_info.append(item[1:])\n",
        "\n",
        "    meta = {\n",
        "        \"continuous_columns\": continuous,\n",
        "        \"discrete_columns\": discrete,\n",
        "        \"column_info\": column_info\n",
        "    }\n",
        "\n",
        "    with open(data_filename) as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    for row in lines:\n",
        "        row_raw = row.split()\n",
        "        row = []\n",
        "        for idx, col in enumerate(row_raw):\n",
        "            if idx in continuous:\n",
        "                row.append(col)\n",
        "            else:\n",
        "                assert idx in discrete\n",
        "                row.append(column_info[idx].index(col))\n",
        "\n",
        "        data.append(row)\n",
        "\n",
        "    return np.asarray(data, dtype='float32'), meta['discrete_columns']\n",
        "\n",
        "\n",
        "def write_tsv(data, meta, output_filename):\n",
        "    with open(output_filename, \"w\") as f:\n",
        "        for row in data:\n",
        "            for idx, col in enumerate(row):\n",
        "                if idx in meta['continuous_columns']:\n",
        "                    print(col, end=' ', file=f)\n",
        "                else:\n",
        "                    assert idx in meta['discrete_columns']\n",
        "                    print(meta['column_info'][idx][int(col)], end=' ', file=f)\n",
        "\n",
        "            print(file=f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmDgUfCKnmwY"
      },
      "source": [
        "# demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj2lmsfCSxB_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "caf0eccc-9f47-4809-9b8e-9e4433d13f22"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "DEMO_URL = 'http://ctgan-data.s3.amazonaws.com/census.csv.gz'\n",
        "\n",
        "\n",
        "def load_demo():\n",
        "    return pd.read_csv(DEMO_URL, compression='gzip')\n",
        "\n",
        "data = load_demo()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "HTTP Error 404: Not Found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fbbbfae95285>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMO_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-fbbbfae95285>\u001b[0m in \u001b[0;36mload_demo\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEMO_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;31m# open URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m     ioargs = _get_filepath_or_buffer(\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# assuming storage_options is to be interpreted as headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mreq_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L03JjbyPnp89"
      },
      "source": [
        "# *** Running DEMO MODEL ***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSZDEJwCS2Ui"
      },
      "source": [
        "data = load_demo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtvDDxr8TAm4"
      },
      "source": [
        "discrete_columns = [\n",
        "    'workclass',\n",
        "    'education',\n",
        "    'marital-status',\n",
        "    'occupation',\n",
        "    'relationship',\n",
        "    'race',\n",
        "    'sex',\n",
        "    'native-country',\n",
        "    'income'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjvSYp7q0C20"
      },
      "source": [
        "# synthesizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra2m_uLvui5c"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.nn import functional\n",
        "\n",
        "#from ctgan.conditional import ConditionalGenerator\n",
        "#from ctgan.models import Discriminator, Generator\n",
        "#from ctgan.sampler import Sampler\n",
        "#from ctgan.transformer import DataTransformer\n",
        "\n",
        "\n",
        "class CTGANSynthesizer(object):\n",
        "    \"\"\"Conditional Table GAN Synthesizer.\n",
        "\n",
        "    This is the core class of the CTGAN project, where the different components\n",
        "    are orchestrated together.\n",
        "\n",
        "    For more details about the process, please check the [Modeling Tabular data using\n",
        "    Conditional GAN](https://arxiv.org/abs/1907.00503) paper.\n",
        "\n",
        "    Args:\n",
        "        embedding_dim (int):\n",
        "            Size of the random sample passed to the Generator. Defaults to 128.\n",
        "        gen_dim (tuple or list of ints):\n",
        "            Size of the output samples for each one of the Residuals. A Resiudal Layer\n",
        "            will be created for each one of the values provided. Defaults to (256, 256).\n",
        "        dis_dim (tuple or list of ints):\n",
        "            Size of the output samples for each one of the Discriminator Layers. A Linear Layer\n",
        "            will be created for each one of the values provided. Defaults to (256, 256).\n",
        "        l2scale (float):\n",
        "            Wheight Decay for the Adam Optimizer. Defaults to 1e-6.\n",
        "        batch_size (int):\n",
        "            Number of data samples to process in each step.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=128, gen_dim=(256, 256), dis_dim=(256, 256),\n",
        "                 l2scale=1e-6, batch_size=500):\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.gen_dim = gen_dim\n",
        "        self.dis_dim = dis_dim\n",
        "\n",
        "        self.l2scale = l2scale\n",
        "        self.batch_size = batch_size\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def _apply_activate(self, data):\n",
        "        data_t = []\n",
        "        st = 0\n",
        "        for item in self.transformer.output_info:\n",
        "            if item[1] == 'tanh':\n",
        "                ed = st + item[0]\n",
        "                data_t.append(torch.tanh(data[:, st:ed]))\n",
        "                st = ed\n",
        "            elif item[1] == 'softmax':\n",
        "                ed = st + item[0]\n",
        "                data_t.append(functional.gumbel_softmax(data[:, st:ed], tau=0.2))\n",
        "                st = ed\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "        return torch.cat(data_t, dim=1)\n",
        "\n",
        "    def _cond_loss(self, data, c, m):\n",
        "        loss = []\n",
        "        st = 0\n",
        "        st_c = 0\n",
        "        skip = False\n",
        "        for item in self.transformer.output_info:\n",
        "            if item[1] == 'tanh':\n",
        "                st += item[0]\n",
        "                skip = True\n",
        "\n",
        "            elif item[1] == 'softmax':\n",
        "                if skip:\n",
        "                    skip = False\n",
        "                    st += item[0]\n",
        "                    continue\n",
        "\n",
        "                ed = st + item[0]\n",
        "                ed_c = st_c + item[0]\n",
        "                tmp = functional.cross_entropy(\n",
        "                    data[:, st:ed],\n",
        "                    torch.argmax(c[:, st_c:ed_c], dim=1),\n",
        "                    reduction='none'\n",
        "                )\n",
        "                loss.append(tmp)\n",
        "                st = ed\n",
        "                st_c = ed_c\n",
        "\n",
        "            else:\n",
        "                assert 0\n",
        "\n",
        "        loss = torch.stack(loss, dim=1)\n",
        "\n",
        "        return (loss * m).sum() / data.size()[0]\n",
        "\n",
        "    def fit(self, train_data, discrete_columns=tuple(), epochs=300, log_frequency=True):\n",
        "        \"\"\"Fit the CTGAN Synthesizer models to the training data.\n",
        "\n",
        "        Args:\n",
        "            train_data (numpy.ndarray or pandas.DataFrame):\n",
        "                Training Data. It must be a 2-dimensional numpy array or a\n",
        "                pandas.DataFrame.\n",
        "            discrete_columns (list-like):\n",
        "                List of discrete columns to be used to generate the Conditional\n",
        "                Vector. If ``train_data`` is a Numpy array, this list should\n",
        "                contain the integer indices of the columns. Otherwise, if it is\n",
        "                a ``pandas.DataFrame``, this list should contain the column names.\n",
        "            epochs (int):\n",
        "                Number of training epochs. Defaults to 300.\n",
        "            log_frequency (boolean):\n",
        "                Whether to use log frequency of categorical levels in conditional\n",
        "                sampling. Defaults to ``True``.\n",
        "        \"\"\"\n",
        "\n",
        "        self.transformer = DataTransformer()\n",
        "        self.transformer.fit(train_data, discrete_columns)\n",
        "        train_data = self.transformer.transform(train_data)\n",
        "\n",
        "        data_sampler = Sampler(train_data, self.transformer.output_info)\n",
        "\n",
        "        data_dim = self.transformer.output_dimensions\n",
        "        self.cond_generator = ConditionalGenerator(\n",
        "            train_data,\n",
        "            self.transformer.output_info,\n",
        "            log_frequency\n",
        "        )\n",
        "\n",
        "        self.generator = Generator(\n",
        "            self.embedding_dim + self.cond_generator.n_opt,\n",
        "            self.gen_dim,\n",
        "            data_dim\n",
        "        ).to(self.device)\n",
        "\n",
        "        discriminator = Discriminator(\n",
        "            data_dim + self.cond_generator.n_opt,\n",
        "            self.dis_dim\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizerG = optim.Adam(\n",
        "            self.generator.parameters(), lr=2e-4, betas=(0.5, 0.9),\n",
        "            weight_decay=self.l2scale\n",
        "        )\n",
        "        optimizerD = optim.Adam(discriminator.parameters(), lr=2e-4, betas=(0.5, 0.9))\n",
        "\n",
        "        assert self.batch_size % 2 == 0\n",
        "        mean = torch.zeros(self.batch_size, self.embedding_dim, device=self.device)\n",
        "        std = mean + 1\n",
        "\n",
        "        steps_per_epoch = max(len(train_data) // self.batch_size, 1)\n",
        "        for i in range(epochs):\n",
        "            for id_ in range(steps_per_epoch):\n",
        "                fakez = torch.normal(mean=mean, std=std)\n",
        "\n",
        "                condvec = self.cond_generator.sample(self.batch_size)\n",
        "                if condvec is None:\n",
        "                    c1, m1, col, opt = None, None, None, None\n",
        "                    real = data_sampler.sample(self.batch_size, col, opt)\n",
        "                else:\n",
        "                    c1, m1, col, opt = condvec\n",
        "                    c1 = torch.from_numpy(c1).to(self.device)\n",
        "                    m1 = torch.from_numpy(m1).to(self.device)\n",
        "                    fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "                    perm = np.arange(self.batch_size)\n",
        "                    np.random.shuffle(perm)\n",
        "                    real = data_sampler.sample(self.batch_size, col[perm], opt[perm])\n",
        "                    c2 = c1[perm]\n",
        "\n",
        "                fake = self.generator(fakez)\n",
        "                fakeact = self._apply_activate(fake)\n",
        "\n",
        "                real = torch.from_numpy(real.astype('float32')).to(self.device)\n",
        "\n",
        "                if c1 is not None:\n",
        "                    fake_cat = torch.cat([fakeact, c1], dim=1)\n",
        "                    real_cat = torch.cat([real, c2], dim=1)\n",
        "                else:\n",
        "                    real_cat = real\n",
        "                    fake_cat = fake\n",
        "\n",
        "                y_fake = discriminator(fake_cat)\n",
        "                y_real = discriminator(real_cat)\n",
        "\n",
        "                pen = discriminator.calc_gradient_penalty(real_cat, fake_cat, self.device)\n",
        "                loss_d = -(torch.mean(y_real) - torch.mean(y_fake))\n",
        "\n",
        "                optimizerD.zero_grad()\n",
        "                pen.backward(retain_graph=True)\n",
        "                loss_d.backward()\n",
        "                optimizerD.step()\n",
        "\n",
        "                fakez = torch.normal(mean=mean, std=std)\n",
        "                condvec = self.cond_generator.sample(self.batch_size)\n",
        "\n",
        "                if condvec is None:\n",
        "                    c1, m1, col, opt = None, None, None, None\n",
        "                else:\n",
        "                    c1, m1, col, opt = condvec\n",
        "                    c1 = torch.from_numpy(c1).to(self.device)\n",
        "                    m1 = torch.from_numpy(m1).to(self.device)\n",
        "                    fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "                fake = self.generator(fakez)\n",
        "                fakeact = self._apply_activate(fake)\n",
        "\n",
        "                if c1 is not None:\n",
        "                    y_fake = discriminator(torch.cat([fakeact, c1], dim=1))\n",
        "                else:\n",
        "                    y_fake = discriminator(fakeact)\n",
        "\n",
        "                if condvec is None:\n",
        "                    cross_entropy = 0\n",
        "                else:\n",
        "                    cross_entropy = self._cond_loss(fake, c1, m1)\n",
        "\n",
        "                loss_g = -torch.mean(y_fake) + cross_entropy\n",
        "\n",
        "                optimizerG.zero_grad()\n",
        "                loss_g.backward()\n",
        "                optimizerG.step()\n",
        "\n",
        "            print(\"Epoch %d, Loss G: %.4f, Loss D: %.4f\" %\n",
        "                  (i + 1, loss_g.detach().cpu(), loss_d.detach().cpu()),\n",
        "                  flush=True)\n",
        "\n",
        "    def sample(self, n):\n",
        "        \"\"\"Sample data similar to the training data.\n",
        "\n",
        "        Args:\n",
        "            n (int):\n",
        "                Number of rows to sample.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray or pandas.DataFrame\n",
        "        \"\"\"\n",
        "\n",
        "        steps = n // self.batch_size + 1\n",
        "        data = []\n",
        "        for i in range(steps):\n",
        "            mean = torch.zeros(self.batch_size, self.embedding_dim)\n",
        "            std = mean + 1\n",
        "            fakez = torch.normal(mean=mean, std=std).to(self.device)\n",
        "\n",
        "            condvec = self.cond_generator.sample_zero(self.batch_size)\n",
        "            if condvec is None:\n",
        "                pass\n",
        "            else:\n",
        "                c1 = condvec\n",
        "                c1 = torch.from_numpy(c1).to(self.device)\n",
        "                fakez = torch.cat([fakez, c1], dim=1)\n",
        "\n",
        "            fake = self.generator(fakez)\n",
        "            fakeact = self._apply_activate(fake)\n",
        "            data.append(fakeact.detach().cpu().numpy())\n",
        "\n",
        "        data = np.concatenate(data, axis=0)\n",
        "        data = data[:n]\n",
        "\n",
        "        return self.transformer.inverse_transform(data, None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVpHzpC0TCm6",
        "outputId": "e20a67f1-f635-476f-9e67-156c5ffa8ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "ctgan = CTGANSynthesizer()\n",
        "ctgan.fit(data.head(200), discrete_columns, epochs=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss G: 1.8432, Loss D: 0.0014\n",
            "Epoch 2, Loss G: 1.9437, Loss D: -0.0222\n",
            "Epoch 3, Loss G: 1.8789, Loss D: -0.0831\n",
            "Epoch 4, Loss G: 1.8896, Loss D: -0.0696\n",
            "Epoch 5, Loss G: 1.7821, Loss D: -0.1089\n",
            "Epoch 6, Loss G: 1.8182, Loss D: -0.1337\n",
            "Epoch 7, Loss G: 1.8646, Loss D: -0.1612\n",
            "Epoch 8, Loss G: 1.8943, Loss D: -0.2277\n",
            "Epoch 9, Loss G: 1.8215, Loss D: -0.2798\n",
            "Epoch 10, Loss G: 1.8213, Loss D: -0.3157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO3EM6t35lre",
        "outputId": "4732c6c7-e100-432a-a5d9-e3870c1b9ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "source": [
        "samples=ctgan.sample(1000)\n",
        "samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>257009</td>\n",
              "      <td>Masters</td>\n",
              "      <td>13</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>178</td>\n",
              "      <td>1533</td>\n",
              "      <td>36</td>\n",
              "      <td>India</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>120091</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>11</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Amer-Indian-Eskimo</td>\n",
              "      <td>Male</td>\n",
              "      <td>13553</td>\n",
              "      <td>-84</td>\n",
              "      <td>43</td>\n",
              "      <td>Iran</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19</td>\n",
              "      <td>Private</td>\n",
              "      <td>244890</td>\n",
              "      <td>9th</td>\n",
              "      <td>11</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>1233</td>\n",
              "      <td>-42</td>\n",
              "      <td>42</td>\n",
              "      <td>Philippines</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>134676</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>-186</td>\n",
              "      <td>-15</td>\n",
              "      <td>52</td>\n",
              "      <td>Germany</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>46</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>103270</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Other</td>\n",
              "      <td>Male</td>\n",
              "      <td>-541</td>\n",
              "      <td>-71</td>\n",
              "      <td>46</td>\n",
              "      <td>Germany</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>18</td>\n",
              "      <td>?</td>\n",
              "      <td>301857</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Amer-Indian-Eskimo</td>\n",
              "      <td>Male</td>\n",
              "      <td>-428</td>\n",
              "      <td>-55</td>\n",
              "      <td>36</td>\n",
              "      <td>Iran</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>49</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>22863</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-AF-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Female</td>\n",
              "      <td>5406</td>\n",
              "      <td>37</td>\n",
              "      <td>51</td>\n",
              "      <td>Canada</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>50</td>\n",
              "      <td>?</td>\n",
              "      <td>415423</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-spouse-absent</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Asian-Pac-Islander</td>\n",
              "      <td>Male</td>\n",
              "      <td>-409</td>\n",
              "      <td>1262</td>\n",
              "      <td>41</td>\n",
              "      <td>Puerto-Rico</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>23</td>\n",
              "      <td>Federal-gov</td>\n",
              "      <td>312093</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>18</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>Amer-Indian-Eskimo</td>\n",
              "      <td>Male</td>\n",
              "      <td>-2687</td>\n",
              "      <td>2215</td>\n",
              "      <td>55</td>\n",
              "      <td>South</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>40</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>220328</td>\n",
              "      <td>Doctorate</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Other-relative</td>\n",
              "      <td>Amer-Indian-Eskimo</td>\n",
              "      <td>Male</td>\n",
              "      <td>-440</td>\n",
              "      <td>-88</td>\n",
              "      <td>72</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows  15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     age          workclass  fnlwgt  ... hours-per-week  native-country  income\n",
              "0     18          State-gov  257009  ...             36           India   <=50K\n",
              "1     42        Federal-gov  120091  ...             43            Iran   <=50K\n",
              "2     19            Private  244890  ...             42     Philippines    >50K\n",
              "3     53          Local-gov  134676  ...             52         Germany    >50K\n",
              "4     46          State-gov  103270  ...             46         Germany    >50K\n",
              "..   ...                ...     ...  ...            ...             ...     ...\n",
              "995   18                  ?  301857  ...             36            Iran   <=50K\n",
              "996   49       Self-emp-inc   22863  ...             51          Canada   <=50K\n",
              "997   50                  ?  415423  ...             41     Puerto-Rico   <=50K\n",
              "998   23        Federal-gov  312093  ...             55           South   <=50K\n",
              "999   40   Self-emp-not-inc  220328  ...             72            Cuba    >50K\n",
              "\n",
              "[1000 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MLhxdeh1rKK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}